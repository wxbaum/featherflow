"""
Executor module for generating and running bash scripts
"""
import os
import json
from pathlib import Path
from typing import Dict, List, Optional, Any
from string import Template
import shlex

# Bash script template as a string
BASH_TEMPLATE = """#!/bin/bash
# Generated by Featherflow - Do not edit manually
# Flow: $flow_name
# Generated: $timestamp

set -e  # Exit on any error

# Set up environment
export FEATHERFLOW_RUN_ID="$run_id"
export FEATHERFLOW_FLOW_NAME="$flow_name"
export FEATHERFLOW_PARAMS='$params_json'

# Create log directory
mkdir -p "$log_dir"

echo "Starting flow: $flow_name (Run ID: $run_id)"
echo "=================================================="

$task_execution_blocks

echo "=================================================="
echo "Flow completed successfully!"
"""

# Task execution block template
TASK_TEMPLATE = """
echo "[$task_id] Starting task..."
$task_command 2>&1 | tee "$log_dir/$task_id.log"
task_status=$${PIPESTATUS[0]}
if [ $task_status -ne 0 ]; then
    echo "[$task_id] Task failed with exit code $task_status"
    exit $task_status
fi
echo "[$task_id] Task completed successfully"
"""

def generate_bash_script(
    flow_def: Dict, 
    tasks_dir: Path,
    params: Optional[Dict] = None
) -> str:
    """
    Generate a bash script to execute the workflow
    
    Args:
        flow_def: Flow definition dictionary
        tasks_dir: Directory containing task scripts
        params: Optional parameters to pass to the tasks
        
    Returns:
        Content of the bash script as a string
    """
    from datetime import datetime
    import uuid
    from .parser import get_execution_order
    
    flow_name = flow_def["name"]
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    run_id = str(uuid.uuid4())
    log_dir = f"./logs/{flow_name}/{run_id}"
    
    # Convert params to JSON string, escaping for shell
    params_json = json.dumps(params or {}).replace("'", "\\'")
    
    # Get execution order based on dependencies
    execution_order = get_execution_order(flow_def["tasks"])
    
    # Create task dictionary for quick lookup
    task_dict = {task["id"]: task for task in flow_def["tasks"]}
    
    # Generate task execution blocks
    task_blocks = []
    for task_id in execution_order:
        task = task_dict[task_id]
        script_path = os.path.join(tasks_dir, task["script"])
        
        # Handle arguments if present
        args = ""
        if "args" in task:
            if isinstance(task["args"], list):
                args = " ".join(shlex.quote(str(arg)) for arg in task["args"])
            elif isinstance(task["args"], dict):
                args = " ".join(f"--{k} {shlex.quote(str(v))}" for k, v in task["args"].items())
            else:
                args = str(task["args"])
        
        # Determine how to execute based on file extension
        if script_path.endswith(".py"):
            cmd = f"python {shlex.quote(script_path)} {args}"
        elif script_path.endswith(".sh"):
            cmd = f"bash {shlex.quote(script_path)} {args}"
        else:
            # Default to executing as a Python script
            cmd = f"python {shlex.quote(script_path)} {args}"
        
        # Add environment variables specific to this task
        env_vars = task.get("env", {})
        env_vars_str = " ".join(f"{k}={shlex.quote(str(v))}" for k, v in env_vars.items())
        if env_vars_str:
            cmd = f"{env_vars_str} {cmd}"
        
        # Create task block
        task_block = Template(TASK_TEMPLATE).substitute(
            task_id=task_id,
            task_command=cmd,
            log_dir=log_dir
        )
        task_blocks.append(task_block)
    
    # Generate full script
    script = Template(BASH_TEMPLATE).substitute(
        flow_name=flow_name,
        timestamp=timestamp,
        run_id=run_id,
        log_dir=log_dir,
        params_json=params_json,
        task_execution_blocks="\n".join(task_blocks)
    )
    
    return script